{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#  сборщик мусора\nimport gc\n# системные команды\nimport sys\n#ошибки\nimport warnings\n# joblib- это набор инструментов для облегчения конвейерной обработки в Python . В частности:\n# прозрачное кеширование функций на диске и ленивая переоценка (шаблон Memoize\n# простые простые параллельные вычисления\nfrom joblib import Parallel, delayed\n# Пути к объектно-ориентированной файловой системе\nfrom pathlib import Path\nimport os\n#  виджеты, представляют собой интерактивные HTML-виджеты для записных книжек Jupyter и ядра IPython.\nimport ipywidgets as widgets\n\n# стандартные\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n# TensorFlow — открытая программная библиотека для машинного обучения, разработанная компанией Google для решения задач построения и тренировки нейронной сети \nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.layers.experimental.preprocessing import StringLookup\nfrom datetime import timedelta\n\nfrom functools import reduce\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm import tqdm\nimport lightgbm as lgbm\n\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T20:08:03.910738Z","iopub.execute_input":"2021-07-28T20:08:03.911337Z","iopub.status.idle":"2021-07-28T20:08:14.663371Z","shell.execute_reply.started":"2021-07-28T20:08:03.911244Z","shell.execute_reply":"2021-07-28T20:08:14.661972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nclass MultiColumnLabelEncoder:\n    def __init__(self,columns = None):\n        self.columns = columns # array of column names to encode\n\n    def fit(self,X,y=None):\n        return self # not relevant here\n\n    def transform(self,X):\n        '''\n        Transforms columns of X specified in self.columns using\n        LabelEncoder(). If no columns specified, transforms all\n        columns in X.\n        '''\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        return self.fit(X,y).transform(X)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:14.665206Z","iopub.execute_input":"2021-07-28T20:08:14.665685Z","iopub.status.idle":"2021-07-28T20:08:14.675481Z","shell.execute_reply.started":"2021-07-28T20:08:14.665613Z","shell.execute_reply":"2021-07-28T20:08:14.674428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### INPUT DATA","metadata":{"execution":{"iopub.status.busy":"2021-07-08T15:30:09.49967Z","iopub.execute_input":"2021-07-08T15:30:09.500255Z","iopub.status.idle":"2021-07-08T15:30:09.50587Z","shell.execute_reply.started":"2021-07-08T15:30:09.500134Z","shell.execute_reply":"2021-07-08T15:30:09.504634Z"}}},{"cell_type":"code","source":"player_target_stats = pd.read_csv('../input/player-target-stats/player_target_stats.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:14.677254Z","iopub.execute_input":"2021-07-28T20:08:14.677556Z","iopub.status.idle":"2021-07-28T20:08:14.737449Z","shell.execute_reply.started":"2021-07-28T20:08:14.677528Z","shell.execute_reply":"2021-07-28T20:08:14.736567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = Path('../input/mlb-pdef-train-dataset')\nrosters = pd.read_pickle(TRAIN_DIR / 'rosters_train.pkl')\ntargets = pd.read_pickle(TRAIN_DIR / 'nextDayPlayerEngagement_train.pkl')\nscores = pd.read_pickle(TRAIN_DIR / 'playerBoxScores_train.pkl')\nplayerTwitter = pd.read_pickle(TRAIN_DIR / 'playerTwitterFollowers_train.pkl')\nteamTwitter = pd.read_pickle(TRAIN_DIR / 'teamTwitterFollowers_train.pkl')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:14.739519Z","iopub.execute_input":"2021-07-28T20:08:14.740307Z","iopub.status.idle":"2021-07-28T20:08:19.473658Z","shell.execute_reply.started":"2021-07-28T20:08:14.74026Z","shell.execute_reply":"2021-07-28T20:08:19.472662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = Path('../input/mlb-player-digital-engagement-forecasting/')\n\ndf_names = ['seasons', 'teams', 'players', 'awards']\n#  читаем файлы создаем ДФ по имени файла\nfor name in df_names:\n    globals()[name] = pd.read_csv(data_dir / f\"{name}.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.475102Z","iopub.execute_input":"2021-07-28T20:08:19.475526Z","iopub.status.idle":"2021-07-28T20:08:19.547016Z","shell.execute_reply.started":"2021-07-28T20:08:19.475483Z","shell.execute_reply":"2021-07-28T20:08:19.546115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pre procesing","metadata":{"execution":{"iopub.status.busy":"2021-07-08T15:30:37.608253Z","iopub.execute_input":"2021-07-08T15:30:37.608609Z","iopub.status.idle":"2021-07-08T15:30:37.612694Z","shell.execute_reply.started":"2021-07-08T15:30:37.608579Z","shell.execute_reply":"2021-07-08T15:30:37.611691Z"}}},{"cell_type":"code","source":"seasons['allStarDate'].fillna(value=pd.to_datetime('1/1/2015'), inplace=True) \n#seasons.fillna('2018-03-29')\nseasons_col = seasons.columns[1:]\nfor col in seasons_col :\n    seasons[col] = pd.to_datetime(seasons[col]).values.astype('datetime64[D]')\n    #seasons[col] = pd.to_datetime(seasons[col], format = '%Y%m%d')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.548377Z","iopub.execute_input":"2021-07-28T20:08:19.54895Z","iopub.status.idle":"2021-07-28T20:08:19.580306Z","shell.execute_reply.started":"2021-07-28T20:08:19.548916Z","shell.execute_reply":"2021-07-28T20:08:19.578896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#seasons","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.58152Z","iopub.execute_input":"2021-07-28T20:08:19.581898Z","iopub.status.idle":"2021-07-28T20:08:19.59476Z","shell.execute_reply.started":"2021-07-28T20:08:19.581863Z","shell.execute_reply":"2021-07-28T20:08:19.593475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# кодировка категориальных в числовые\nplayers['label_playerId'] = players['playerId']\n# df_coding_col = ['label_playerId']\n# train = MultiColumnLabelEncoder(columns = df_coding_col).fit_transform(train)\ndf_coding_columns = ['primaryPositionName','birthCountry' , 'label_playerId']\nplayers = MultiColumnLabelEncoder(columns = df_coding_columns).fit_transform(players)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.59832Z","iopub.execute_input":"2021-07-28T20:08:19.598765Z","iopub.status.idle":"2021-07-28T20:08:19.615529Z","shell.execute_reply.started":"2021-07-28T20:08:19.598721Z","shell.execute_reply":"2021-07-28T20:08:19.614375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_col = ['mlbDebutDate','DOB']\nfor col in time_col :\n    players[col] = pd.to_datetime(players[col]).values.astype('datetime64[D]')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.620145Z","iopub.execute_input":"2021-07-28T20:08:19.620531Z","iopub.status.idle":"2021-07-28T20:08:19.643388Z","shell.execute_reply.started":"2021-07-28T20:08:19.620495Z","shell.execute_reply":"2021-07-28T20:08:19.642155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nfrom datetime import date","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.646471Z","iopub.execute_input":"2021-07-28T20:08:19.647132Z","iopub.status.idle":"2021-07-28T20:08:19.652981Z","shell.execute_reply.started":"2021-07-28T20:08:19.647091Z","shell.execute_reply":"2021-07-28T20:08:19.651804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players['birthday_year'] = pd.DatetimeIndex(players['DOB']).year\nplayers['Debut_year'] = pd.DatetimeIndex(players['mlbDebutDate']).year","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.656649Z","iopub.execute_input":"2021-07-28T20:08:19.657046Z","iopub.status.idle":"2021-07-28T20:08:19.672811Z","shell.execute_reply.started":"2021-07-28T20:08:19.657012Z","shell.execute_reply":"2021-07-28T20:08:19.671338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#   пока только количество лет\ndef udate_year_old(df):\n    df['date_year'] = pd.to_datetime(df['date'], format = '%Y%m%d')\n    df['date_year'] = pd.DatetimeIndex(df['date_year']).year\n    newColumn = lambda x: x['date_year'] - x['birthday_year']\n    df['year_old'] = df.apply(newColumn, axis=1)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.675427Z","iopub.execute_input":"2021-07-28T20:08:19.675778Z","iopub.status.idle":"2021-07-28T20:08:19.68544Z","shell.execute_reply.started":"2021-07-28T20:08:19.675748Z","shell.execute_reply":"2021-07-28T20:08:19.684004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# today = date.today()\n# print(today.year)\n# type(today.year)\n# players['year_old'] = players['year'].apply(lambda x:  today.year - x)\n# players['Debut_old'] = players['Debut_year'].apply(lambda x:  today.year - x)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.686747Z","iopub.execute_input":"2021-07-28T20:08:19.687036Z","iopub.status.idle":"2021-07-28T20:08:19.700114Z","shell.execute_reply.started":"2021-07-28T20:08:19.68701Z","shell.execute_reply":"2021-07-28T20:08:19.69856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.701718Z","iopub.execute_input":"2021-07-28T20:08:19.702024Z","iopub.status.idle":"2021-07-28T20:08:19.765232Z","shell.execute_reply.started":"2021-07-28T20:08:19.701996Z","shell.execute_reply":"2021-07-28T20:08:19.764206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#players.info()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.766601Z","iopub.execute_input":"2021-07-28T20:08:19.766932Z","iopub.status.idle":"2021-07-28T20:08:19.771497Z","shell.execute_reply.started":"2021-07-28T20:08:19.766902Z","shell.execute_reply":"2021-07-28T20:08:19.770336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Отбираем только игроков участвующих в замерах playerForTestSetAndFuturePreds = True\npids_test = players.playerId.loc[ players.playerForTestSetAndFuturePreds.fillna(False)].astype(str)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.772942Z","iopub.execute_input":"2021-07-28T20:08:19.773257Z","iopub.status.idle":"2021-07-28T20:08:19.793081Z","shell.execute_reply.started":"2021-07-28T20:08:19.773225Z","shell.execute_reply":"2021-07-28T20:08:19.79189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores.fillna(0, inplace=True)\nscores = scores.groupby(['playerId', 'date']).sum().reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:19.794826Z","iopub.execute_input":"2021-07-28T20:08:19.7955Z","iopub.status.idle":"2021-07-28T20:08:20.785237Z","shell.execute_reply.started":"2021-07-28T20:08:19.795453Z","shell.execute_reply":"2021-07-28T20:08:20.784297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#   пока только Сизон Да/нет  и этап сизона\ndef udate_season(df):\n    df['year'] = df.index.year\n    df['month'] = df.index.month\n    #df['date'] = df.index.to_timestamp()\n    df['date_id'] = df.index.to_timestamp()\n    #display(df)\n    #df['date_id'] = df['date']\n    \n    # Собираем вместе сезоны и даты\n    dates_with_info = pd.merge( df, seasons,  left_on = 'year', right_on = 'seasonId')\n    # Create date index\n#     dates_with_info['period'] = dates_with_info['date']\n#     dates_with_info['period'] = pd.to_datetime(train['period'], format = '%Y%m%d')\n#     dates_with_info['date'] = pd.PeriodIndex(dates_with_info.date, freq='D')\n    \n    dates_with_info['inSeason'] = ( dates_with_info['date_id'].between( dates_with_info['regularSeasonStartDate'], dates_with_info['postSeasonEndDate'],\n    inclusive = True ) )\n    # Separate dates into different parts of MLB season\n    dates_with_info['seasonPart'] = np.select(\n      [\n        dates_with_info['date_id'] < dates_with_info['preSeasonStartDate'], \n        dates_with_info['date_id'] < dates_with_info['regularSeasonStartDate'],\n        dates_with_info['date_id'] <= dates_with_info['lastDate1stHalf'],\n        dates_with_info['date_id'] < dates_with_info['firstDate2ndHalf'],\n        dates_with_info['date_id'] <= dates_with_info['regularSeasonEndDate'],\n        dates_with_info['date_id'] < dates_with_info['postSeasonStartDate'],\n        dates_with_info['date_id'] <= dates_with_info['postSeasonEndDate'],\n        dates_with_info['date_id'] > dates_with_info['postSeasonEndDate']\n      ], \n      [  -1,1,2,3,4,2,1,-1 ], \n      default = np.nan\n      )\n    \n\n#     [ 'Offseason', 'Preseason', 'Reg Season 1st Half','All-Star Break','Reg Season 2nd Half','Between Reg and Postseason','Postseason','Offseason' ], \n    \n     \n    \n    #display(dates_with_info)\n    dates_with_info = dates_with_info.drop(['preSeasonEndDate', 'regularSeasonStartDate','regularSeasonEndDate','lastDate1stHalf',\n                  'allStarDate',       'firstDate2ndHalf', 'postSeasonStartDate','postSeasonEndDate', 'seasonStartDate','seasonEndDate',\n                  'preSeasonStartDate','seasonId' ,'date_id', 'year', 'month'], axis =1 )\n             \n    \n    df = dates_with_info\n    #df = df.set_index('date')\n    df = df.astype({'inSeason':'int32'})  \n    df_col = ['inSeason','seasonPart']\n    df = df.astype({name: np.float32 for name in df_col})\n    del dates_with_info\n    gc.collect();\n    #display(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:20.786425Z","iopub.execute_input":"2021-07-28T20:08:20.786877Z","iopub.status.idle":"2021-07-28T20:08:20.7983Z","shell.execute_reply.started":"2021-07-28T20:08:20.786835Z","shell.execute_reply":"2021-07-28T20:08:20.79735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### playerTwitter","metadata":{}},{"cell_type":"code","source":"# Добавляем период для стыковки с данными\nplayerTwitter['period'] = pd.to_datetime(playerTwitter['date'], format = '%Y%m%d')\nplayerTwitter['twit_year'] = playerTwitter['period'].dt.year\nplayerTwitter['twit_month'] = playerTwitter['period'].dt.month","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:20.799427Z","iopub.execute_input":"2021-07-28T20:08:20.799942Z","iopub.status.idle":"2021-07-28T20:08:20.832542Z","shell.execute_reply.started":"2021-07-28T20:08:20.799899Z","shell.execute_reply":"2021-07-28T20:08:20.831556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# расчет медианного значения\nmed_followers = pd.DataFrame(playerTwitter.groupby('playerId')['numberOfFollowers'].median().sort_values(ascending=False)).reset_index()\nmed_followers.columns = ['playerId', 'twit_med_f']\n\nmin_followers = pd.DataFrame(playerTwitter.groupby('playerId').agg({'numberOfFollowers':'min'})['numberOfFollowers']).reset_index()\nmin_followers.columns = ['playerId', 'twit_min_f']\n\nmax_followers = pd.DataFrame(playerTwitter.groupby('playerId').agg({'numberOfFollowers':'max'})['numberOfFollowers']).reset_index()\nmax_followers.columns = ['playerId', 'twit_max_f']\n\ndef udate_playTwiter(df):\n    df = df.merge(med_followers , on =['playerId'], how = 'left')\n    df = df.merge(min_followers , on =['playerId'], how = 'left')\n    df = df.merge(max_followers , on =['playerId'], how = 'left')\n    \n    newColumn2 = lambda x: x['numberOfFollowers'] - x['twit_med_f']\n    df['twit_trend'] = df.apply(newColumn2, axis=1) \n    return df\n\nplayerTwitter = udate_playTwiter(playerTwitter)\nplayerTwitter.head()\n\n\n_index = (playerTwitter['date'] == 20210401)\nplayerTwitter_test = playerTwitter.loc[_index].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:20.833776Z","iopub.execute_input":"2021-07-28T20:08:20.83424Z","iopub.status.idle":"2021-07-28T20:08:21.873517Z","shell.execute_reply.started":"2021-07-28T20:08:20.834192Z","shell.execute_reply":"2021-07-28T20:08:21.872667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## teamTwit","metadata":{}},{"cell_type":"code","source":"# Добавляем период для стыковки с данными\nteamTwitter.columns = ['date','teamId','teamName','accountName','twitterHandle','team_numberOfFollowers' ,'index']\n\nteamTwitter['period'] = pd.to_datetime(teamTwitter['date'], format = '%Y%m%d')\nteamTwitter['twit_year'] = teamTwitter['period'].dt.year\nteamTwitter['twit_month'] = teamTwitter['period'].dt.month","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:21.87472Z","iopub.execute_input":"2021-07-28T20:08:21.875189Z","iopub.status.idle":"2021-07-28T20:08:21.885822Z","shell.execute_reply.started":"2021-07-28T20:08:21.875147Z","shell.execute_reply":"2021-07-28T20:08:21.884751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# расчет медианного значения\nmed_followers_team = pd.DataFrame(teamTwitter.groupby('teamId')['team_numberOfFollowers'].median().sort_values(ascending=False)).reset_index()\nmed_followers_team.columns = ['teamId', 'team_twit_med_f']\n\nmin_followers_team = pd.DataFrame(teamTwitter.groupby('teamId').agg({'team_numberOfFollowers':'min'})['team_numberOfFollowers']).reset_index()\nmin_followers_team.columns = ['teamId', 'team_twit_min_f']\n\nmax_followers_team = pd.DataFrame(teamTwitter.groupby('teamId').agg({'team_numberOfFollowers':'max'})['team_numberOfFollowers']).reset_index()\nmax_followers_team.columns = ['teamId', 'team_twit_max_f']\n\ndef udate_teamTwiter(df):\n    df = df.merge(med_followers_team , on =['teamId'], how = 'left')\n    df = df.merge(min_followers_team , on =['teamId'], how = 'left')\n    df = df.merge(max_followers_team , on =['teamId'], how = 'left')\n    \n    newColumn2 = lambda x: x['team_numberOfFollowers'] - x['team_twit_med_f']\n    df['team_twit_trend'] = df.apply(newColumn2, axis=1) \n    return df\n\nteamTwitter = udate_teamTwiter(teamTwitter)\nteamTwitter.head()\n\n\n_index = (teamTwitter['date'] == 20210401)\nteamTwitter_test = teamTwitter.loc[_index].reset_index(drop=True)\n\ndel med_followers_team ,min_followers_team ,max_followers_team\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:21.887564Z","iopub.execute_input":"2021-07-28T20:08:21.887926Z","iopub.status.idle":"2021-07-28T20:08:22.165236Z","shell.execute_reply.started":"2021-07-28T20:08:21.887893Z","shell.execute_reply":"2021-07-28T20:08:22.16412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Target team","metadata":{}},{"cell_type":"code","source":"rosters_tag = targets.merge(rosters, on=['playerId','date'], how='left')\nteam_tag_sum =  rosters_tag.groupby(['teamId','date'])['target1'].agg('sum').reset_index()\nteam_tag_sum.columns = ['teamId', 'date','targ_team']\nteam_tag_sum.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:22.170271Z","iopub.execute_input":"2021-07-28T20:08:22.170614Z","iopub.status.idle":"2021-07-28T20:08:23.976169Z","shell.execute_reply.started":"2021-07-28T20:08:22.170583Z","shell.execute_reply":"2021-07-28T20:08:23.975384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LGBM  DATA","metadata":{"execution":{"iopub.status.busy":"2021-07-08T15:38:23.88374Z","iopub.execute_input":"2021-07-08T15:38:23.88412Z","iopub.status.idle":"2021-07-08T15:38:23.887857Z","shell.execute_reply.started":"2021-07-08T15:38:23.884085Z","shell.execute_reply":"2021-07-08T15:38:23.886876Z"}}},{"cell_type":"code","source":"players_cols = ['playerId', 'primaryPositionName', 'label_playerId', 'birthday_year']\ntargets_cols = ['playerId', 'target1', 'target2', 'target3', 'target4' ,'date']\nrosters_cols = ['playerId', 'teamId','status', 'date']\nscores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances', 'date']\n\nplayerTwitter_cols = ['playerId','numberOfFollowers', 'twit_year','twit_month','twit_med_f' , 'twit_min_f', 'twit_max_f','twit_trend']\n# here++++++++++++++++++++++++++++++++\nteamTwitter_cols = ['teamId','team_numberOfFollowers', 'twit_year','twit_month','team_twit_med_f' , 'team_twit_min_f', 'team_twit_max_f','team_twit_trend']\n# here++++++++++++++++++++++++++++++++","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:23.978086Z","iopub.execute_input":"2021-07-28T20:08:23.978665Z","iopub.status.idle":"2021-07-28T20:08:23.988356Z","shell.execute_reply.started":"2021-07-28T20:08:23.9786Z","shell.execute_reply":"2021-07-28T20:08:23.987154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = targets[targets_cols].merge(players[players_cols], on=['playerId'], how='left')\ntrain = train.merge(scores[scores_cols], on=['playerId', 'date'], how='left')\ntrain = train.merge(rosters[rosters_cols], on=['playerId', 'date'], how='left')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:23.989937Z","iopub.execute_input":"2021-07-28T20:08:23.990306Z","iopub.status.idle":"2021-07-28T20:08:29.030471Z","shell.execute_reply.started":"2021-07-28T20:08:23.990274Z","shell.execute_reply":"2021-07-28T20:08:29.029341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['period'] = train['date']\ntrain['period'] = pd.to_datetime(train['period'], format = '%Y%m%d')\n# here++++++++++++++++++++++++\ntrain['twit_year'] = train['period'].dt.year\ntrain['twit_month'] = train['period'].dt.month\n#+++++++++++++++++++++++++++++\ntrain = train.set_index('period').to_period('D')\ntrain = udate_season(train)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:29.031962Z","iopub.execute_input":"2021-07-28T20:08:29.032282Z","iopub.status.idle":"2021-07-28T20:08:37.91996Z","shell.execute_reply.started":"2021-07-28T20:08:29.03225Z","shell.execute_reply":"2021-07-28T20:08:37.918809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обогащаем twiterom\ntrain = train.merge(playerTwitter[playerTwitter_cols], on=['playerId', 'twit_year','twit_month'], how='left')\n#train.fillna({'numberOfFollowers':0, 'twit_trend':0}, inplace=True)\ntrain.fillna({'numberOfFollowers':0, 'twit_med_f':0 , 'twit_min_f':0 ,'twit_max_f':0 ,'twit_trend':0 }, inplace=True)\n#train.fillna(0,inplace=True)\n#train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:37.9213Z","iopub.execute_input":"2021-07-28T20:08:37.921599Z","iopub.status.idle":"2021-07-28T20:08:41.17622Z","shell.execute_reply.started":"2021-07-28T20:08:37.921569Z","shell.execute_reply":"2021-07-28T20:08:41.174997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обогащаем twiterom team\ntrain = train.merge(teamTwitter[teamTwitter_cols], on=['teamId', 'twit_year','twit_month'], how='left')\n#train.fillna({'numberOfFollowers':0, 'twit_trend':0}, inplace=True)\ntrain.fillna({'team_numberOfFollowers':0, 'team_twit_med_f':0 , 'team_twit_min_f':0 ,'team_twit_max_f':0 ,'team_twit_trend':0 }, inplace=True)\n#'team_twit_med_f' , 'team_twit_min_f', 'team_twit_max_f','team_twit_trend']\n#train.fillna(0,inplace=True)\n#train.head()\ntrain['team_numberOfFollowers'].value_counts()\ndel teamTwitter ,playerTwitter\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:41.177639Z","iopub.execute_input":"2021-07-28T20:08:41.177966Z","iopub.status.idle":"2021-07-28T20:08:46.713766Z","shell.execute_reply.started":"2021-07-28T20:08:41.177933Z","shell.execute_reply":"2021-07-28T20:08:46.712531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обогащаем командной целью\ntrain = train.merge(team_tag_sum, on=['teamId', 'date'], how='left')\n#train.fillna({'numberOfFollowers':0, 'twit_trend':0}, inplace=True)\ntrain.fillna({'targ_team':0}, inplace=True)\ntrain['targ_team'].value_counts()\ndel team_tag_sum\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:46.715527Z","iopub.execute_input":"2021-07-28T20:08:46.716004Z","iopub.status.idle":"2021-07-28T20:08:52.239632Z","shell.execute_reply.started":"2021-07-28T20:08:46.715953Z","shell.execute_reply":"2021-07-28T20:08:52.238496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train =  udate_year_old(train)\n# train['date_year'] = pd.to_datetime(train['date'], format = '%Y%m%d')\n# train['date_year'] = pd.DatetimeIndex(train['date_year']).year\n# newColumn = lambda x: x['date_year'] - x['birthday_year']\n# train['year_old'] = train.apply(newColumn, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:08:52.240979Z","iopub.execute_input":"2021-07-28T20:08:52.2413Z","iopub.status.idle":"2021-07-28T20:09:59.054745Z","shell.execute_reply.started":"2021-07-28T20:08:52.241269Z","shell.execute_reply":"2021-07-28T20:09:59.053514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:09:59.056321Z","iopub.execute_input":"2021-07-28T20:09:59.05675Z","iopub.status.idle":"2021-07-28T20:09:59.064089Z","shell.execute_reply.started":"2021-07-28T20:09:59.056701Z","shell.execute_reply":"2021-07-28T20:09:59.061333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:09:59.06581Z","iopub.execute_input":"2021-07-28T20:09:59.066574Z","iopub.status.idle":"2021-07-28T20:10:10.852526Z","shell.execute_reply.started":"2021-07-28T20:09:59.066517Z","shell.execute_reply":"2021-07-28T20:10:10.851403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_cols = ['battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances',\n       'inSeason' , 'seasonPart',        \n       'target1_mean', 'target1_median', 'target1_std', 'target1_min', 'target1_max', 'target1_prob',\n       'target2_mean', 'target2_median', 'target2_std', 'target2_min', 'target2_max', 'target2_prob',\n       'target3_mean', 'target3_median', 'target3_std', 'target3_min', 'target3_max', 'target3_prob',\n       'target4_mean', 'target4_median', 'target4_std', 'target4_min', 'target4_max', 'target4_prob',\n       # This +++++++++++ ''\n       'label_playerId', 'label_teamId', 'label_status','year_old','numberOfFollowers', 'twit_med_f' , 'twit_min_f', 'twit_max_f','twit_trend',\n        'team_twit_med_f' , 'team_twit_min_f', 'team_twit_max_f','team_twit_trend','team_numberOfFollowers']\nfeature_cols_2 = feature_cols +['target1','targ_team']","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:10:10.854048Z","iopub.execute_input":"2021-07-28T20:10:10.854381Z","iopub.status.idle":"2021-07-28T20:10:10.864484Z","shell.execute_reply.started":"2021-07-28T20:10:10.854347Z","shell.execute_reply":"2021-07-28T20:10:10.863466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label encoding\nteamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\nstatus2num = {c: i for i, c in enumerate(train['status'].unique())}\ntrain['label_teamId'] = train['teamId'].map(teamid2num)\ntrain['label_status'] = train['status'].map(status2num)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:10:10.865792Z","iopub.execute_input":"2021-07-28T20:10:10.866091Z","iopub.status.idle":"2021-07-28T20:10:11.564427Z","shell.execute_reply.started":"2021-07-28T20:10:10.866061Z","shell.execute_reply":"2021-07-28T20:10:11.563372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test_split\ntrain_X = train[feature_cols]\ntrain_y = train[['target1', 'target2', 'target3', 'target4']]\n\n_index = (train['date'] < 20210401)\nx_train = train_X.loc[_index].reset_index(drop=True)\ny_train = train_y.loc[_index].reset_index(drop=True)\nx_valid = train_X.loc[~_index].reset_index(drop=True)\ny_valid = train_y.loc[~_index].reset_index(drop=True)\n\nprint(x_train.shape)\nprint(x_valid.shape)\nprint(y_train.shape)\nprint(y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:10:11.565932Z","iopub.execute_input":"2021-07-28T20:10:11.566267Z","iopub.status.idle":"2021-07-28T20:10:15.948904Z","shell.execute_reply.started":"2021-07-28T20:10:11.566236Z","shell.execute_reply":"2021-07-28T20:10:15.947762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test_split\ntrain_X_2 = train[feature_cols_2]\ntrain_y = train[['target1', 'target2', 'target3', 'target4']]\n\n_index = (train['date'] < 20210401)\nx_train_2 = train_X_2.loc[_index].reset_index(drop=True)\ny_train = train_y.loc[_index].reset_index(drop=True)\nx_valid_2 = train_X_2.loc[~_index].reset_index(drop=True)\ny_valid = train_y.loc[~_index].reset_index(drop=True)\n\nprint(x_train_2.shape)\nprint(x_valid_2.shape)\nprint(y_train.shape)\nprint(y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:10:15.950261Z","iopub.execute_input":"2021-07-28T20:10:15.950577Z","iopub.status.idle":"2021-07-28T20:10:18.712889Z","shell.execute_reply.started":"2021-07-28T20:10:15.950545Z","shell.execute_reply":"2021-07-28T20:10:18.711732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train , train_X_2 ,train_X\ngc.collect();","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:10:18.714199Z","iopub.execute_input":"2021-07-28T20:10:18.714485Z","iopub.status.idle":"2021-07-28T20:10:18.957562Z","shell.execute_reply.started":"2021-07-28T20:10:18.714458Z","shell.execute_reply":"2021-07-28T20:10:18.956575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### KER  DATA","metadata":{"execution":{"iopub.status.busy":"2021-07-08T15:49:03.274909Z","iopub.execute_input":"2021-07-08T15:49:03.275301Z","iopub.status.idle":"2021-07-08T15:49:03.279302Z","shell.execute_reply.started":"2021-07-08T15:49:03.275264Z","shell.execute_reply":"2021-07-08T15:49:03.278204Z"}}},{"cell_type":"code","source":"ROOT_DIR = \"../input/mlb-player-digital-engagement-forecasting\"\n#=======================#\ndef flatten(df, col):\n    du = (df.pivot(index=\"playerId\", columns=\"EvalDate\", \n               values=col).add_prefix(f\"{col}_\").\n      rename_axis(None, axis=1).reset_index())\n    return du\n#============================#\n#============================#\ndef reducer(left, right):\n    return left.merge(right, on=\"playerId\")\n#========================\nTGTCOLS = [\"target1\",\"target2\",\"target3\",\"target4\"]\ndef test_lag(sub):\n    sub[\"playerId\"] = sub[\"date_playerId\"].apply(lambda s: int(  s.split(\"_\")[1]  ) )\n    assert sub.date.nunique() == 1\n    dte = sub[\"date\"].unique()[0]\n    \n    eval_dt = pd.to_datetime(dte, format=\"%Y%m%d\")\n    dtes = [eval_dt + timedelta(days=-k) for k in LAGS]\n    mp_dtes = {eval_dt + timedelta(days=-k):k for k in LAGS}\n    \n    sl = LAST.loc[LAST.EvalDate.between(dtes[-1], dtes[0]), [\"EvalDate\",\"playerId\"]+TGTCOLS].copy()\n    sl[\"EvalDate\"] = sl[\"EvalDate\"].map(mp_dtes)\n    du = [flatten(sl, col) for col in TGTCOLS]\n    du = reduce(reducer, du)\n    return du, eval_dt\n\n#  загружаем  цели , переводим дату во время , добавляем колонку год\ntr = pd.read_csv(\"../input/mlb-data/target.csv\")\nprint(tr.shape)\ngc.collect()\ntr[\"EvalDate\"] = pd.to_datetime(tr[\"EvalDate\"])\ntr[\"EvalDate\"] = tr[\"EvalDate\"] + timedelta(days=-1)\ntr[\"EvalYear\"] = tr[\"EvalDate\"].dt.year\n\nMED_DF = tr.groupby([\"playerId\",\"EvalYear\"])[TGTCOLS].median().reset_index()\n# переименовывают колонки на медиану\nMEDCOLS = [\"tgt1_med\",\"tgt2_med\", \"tgt3_med\", \"tgt4_med\"]\nMED_DF.columns = [\"playerId\",\"EvalYear\"] + MEDCOLS\nLAGS = list(range(1,21))\n#LAGS\n# генерит колонки новых фич - лагов\nFECOLS = [f\"{col}_{lag}\" for lag in reversed(LAGS) for col in TGTCOLS]\ndef train_lag(df, lag=1):\n    dp = df[[\"playerId\",\"EvalDate\"]+TGTCOLS].copy()\n    # добавляем лаг от 1 до 20 дней timedelta(days=lag) в текущий день пишуться предыдущие значения\n    dp[\"EvalDate\"]  =dp[\"EvalDate\"] + timedelta(days=lag) \n    df = df.merge(dp, on=[\"playerId\", \"EvalDate\"], suffixes=[\"\",f\"_{lag}\"], how=\"left\")\n    return df\n#=================================\nfor lag in tqdm(LAGS):\n    tr = train_lag(tr, lag=lag)\n    gc.collect()\n#===========\ntr = tr.sort_values(by=[\"playerId\", \"EvalDate\"])\nprint(tr.shape)\n# удаляем строки в которых есть пустые значения\ntr = tr.dropna()\nprint(tr.shape)\n\n#tr.head()\ntr = tr.merge(MED_DF, on=[\"playerId\",\"EvalYear\"])\ngc.collect()\n#tr.head()\n#FECOLS\n#MEDCOLS\n\nX = tr[FECOLS+MEDCOLS].values\ny = tr[TGTCOLS].values\ncl = tr[\"playerId\"].values\n\nNFOLDS = 6\nskf = StratifiedKFold(n_splits=NFOLDS)\nfolds = skf.split(X, cl)\nfolds = list(folds)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:10:18.958967Z","iopub.execute_input":"2021-07-28T20:10:18.959305Z","iopub.status.idle":"2021-07-28T20:11:37.775767Z","shell.execute_reply.started":"2021-07-28T20:10:18.959273Z","shell.execute_reply":"2021-07-28T20:11:37.774686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\ntf.random.set_seed(777)\n#tf.random.set_seed(777)\n\ndef make_model(n_in):\n    inp = L.Input(name=\"inputs\", shape=(n_in,))\n    x = L.Dense(50, activation=\"relu\", name=\"d1\")(inp)\n    x = L.Dense(50, activation=\"relu\", name=\"d2\")(x)\n    preds = L.Dense(4, activation=\"linear\", name=\"preds\")(x)\n    \n    model = M.Model(inp, preds, name=\"ANN\")\n    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n    return model\n\nnet = make_model(X.shape[1])\nprint(net.summary())\n\noof = np.zeros(y.shape)\nnets = []\nfor idx in range(NFOLDS):\n    print(\"FOLD:\", idx)\n    tr_idx, val_idx = folds[idx]\n    ckpt = ModelCheckpoint(f\"w{idx}.h5\", monitor='val_loss', verbose=1, save_best_only=True,mode='min')\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, min_lr=0.0005)\n    es = EarlyStopping(monitor='val_loss', patience=6)\n    reg = make_model(X.shape[1])\n#     reg.fit(X[tr_idx], y[tr_idx], epochs=10, batch_size=35_000, validation_data=(X[val_idx], y[val_idx]),\n#             verbose=1, callbacks=[ckpt, reduce_lr, es])\n# Для ускорения читаем сохраненные веса\n    reg.load_weights(f\"../input/try-something-silly-1/w{idx}.h5\")\n    #reg.load_weights(f\"w{idx}.h5\")\n    oof[val_idx] = reg.predict(X[val_idx], batch_size=50_000, verbose=1)\n    nets.append(reg)\n    gc.collect()\n    #\n#\n\nmae = mean_absolute_error(y, oof)\nmse = mean_squared_error(y, oof, squared=False)\nprint(\"mae:\", mae)\nprint(\"mse:\", mse)\n\n# Historical information to use in prediction time\nbound_dt = pd.to_datetime(\"2021-01-01\")\nLAST = tr.loc[tr.EvalDate>bound_dt].copy()\n\nLAST_MED_DF = MED_DF.loc[MED_DF.EvalYear==2021].copy()\nLAST_MED_DF.drop(\"EvalYear\", axis=1, inplace=True)\ndel tr\n\n#\"\"\"\nimport mlb\nFE = []; SUB = [];","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:37.777412Z","iopub.execute_input":"2021-07-28T20:11:37.777778Z","iopub.status.idle":"2021-07-28T20:11:43.42583Z","shell.execute_reply.started":"2021-07-28T20:11:37.777746Z","shell.execute_reply":"2021-07-28T20:11:43.424858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:15:36.404143Z","iopub.execute_input":"2021-07-09T11:15:36.404478Z","iopub.status.idle":"2021-07-09T11:15:36.409825Z","shell.execute_reply.started":"2021-07-09T11:15:36.404409Z","shell.execute_reply":"2021-07-09T11:15:36.408593Z"}}},{"cell_type":"markdown","source":"#### Model LGBM","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:16:04.566829Z","iopub.execute_input":"2021-07-09T11:16:04.567194Z","iopub.status.idle":"2021-07-09T11:16:04.570077Z","shell.execute_reply.started":"2021-07-09T11:16:04.56717Z","shell.execute_reply":"2021-07-09T11:16:04.569206Z"}}},{"cell_type":"code","source":"from sklearn.linear_model import LassoCV, RidgeCV , MultiTaskLassoCV\nimport matplotlib.pyplot as plt                  # plots\nimport seaborn as sns                            # more plots\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score, TimeSeriesSplit\nimport lightgbm as lgbm\nfrom sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:43.42707Z","iopub.execute_input":"2021-07-28T20:11:43.427373Z","iopub.status.idle":"2021-07-28T20:11:43.526665Z","shell.execute_reply.started":"2021-07-28T20:11:43.427345Z","shell.execute_reply":"2021-07-28T20:11:43.525479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_lgbm(x_train, y_train, x_valid, y_valid, target , params: dict=None, verbose=100):\n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n    if os.path.isfile(f'../input/mbl-lgbm-test/model_lgb_{target}.pkl'):\n        with open(f'../input/mbl-lgbm-test/model_lgb_{target}.pkl', 'rb') as fin:\n            print('open', target)\n            model = pickle.load(fin)\n    else:\n        model = lgbm.LGBMRegressor(**params)\n        model.fit(x_train, y_train,eval_set=[(x_valid, y_valid)],early_stopping_rounds=verbose,verbose=verbose)\n        with open(f'model_lgb_{target}.pkl', 'wb') as handle:\n            pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n    oof_pred = model.predict(x_valid)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:43.528202Z","iopub.execute_input":"2021-07-28T20:11:43.528645Z","iopub.status.idle":"2021-07-28T20:11:43.538217Z","shell.execute_reply.started":"2021-07-28T20:11:43.528571Z","shell.execute_reply":"2021-07-28T20:11:43.536983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params1 = {\n   'objective':'mae',\n   'reg_alpha': 0.14947461820098767, \n   'reg_lambda': 0.10185644384043743, \n   'n_estimators': 3633, \n   'learning_rate': 0.08046301304430488, \n   'num_leaves': 674, \n   'feature_fraction': 0.9101240539122566, \n   'bagging_fraction': 0.9884451442950513, \n   'bagging_freq': 8,\n   'min_child_samples': 51\n}\n\nparams2 = {\n 'objective':'mae',\n 'reg_alpha': 0.1,\n 'reg_lambda': 0.1, \n 'n_estimators': 80,\n 'learning_rate': 0.1,\n 'random_state': 42,\n \"num_leaves\": 22\n}\n\nparams4 = {\n  'objective':'mae',\n  'reg_alpha': 0.016468100279441976, \n  'reg_lambda': 0.09128335764019105,\n  'n_estimators': 9868, \n  'learning_rate': 0.10528150510326864, \n  'num_leaves': 157, \n  'feature_fraction': 0.5419185713426886, \n  'bagging_fraction': 0.2637405128936662, \n  'bagging_freq': 19, \n  'min_child_samples': 71\n}\n\nparams3 = {\n 'objective':'mae',\n 'reg_alpha': 0.1,\n 'reg_lambda': 0.1, \n 'n_estimators': 10000,\n 'learning_rate': 0.1,\n 'random_state': 42,\n \"num_leaves\": 100\n}\n\nparams = {\n 'objective':'mae',\n 'reg_alpha': 0.1,\n 'reg_lambda': 0.1, \n 'n_estimators': 100000,\n 'learning_rate': 0.1,\n 'random_state': 42,\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:43.539769Z","iopub.execute_input":"2021-07-28T20:11:43.540196Z","iopub.status.idle":"2021-07-28T20:11:43.551448Z","shell.execute_reply.started":"2021-07-28T20:11:43.540152Z","shell.execute_reply":"2021-07-28T20:11:43.550366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof1, model1, score1 = fit_lgbm(\n    x_train, y_train['target1'],\n    x_valid, y_valid['target1'],\n    1,\n    params1\n    #params\n)\n\noof2, model2, score2 = fit_lgbm(\n    x_train_2, y_train['target2'],\n    x_valid_2, y_valid['target2'],\n    2,\n    params2\n    #params\n)\n\noof3, model3, score3 = fit_lgbm(\n    x_train_2, y_train['target3'],\n    x_valid_2, y_valid['target3'],\n    3,\n    params3\n    #params\n)\n\noof4, model4, score4 = fit_lgbm(\n    x_train_2, y_train['target4'],\n    x_valid_2, y_valid['target4'],\n    4,\n    params4\n    #params\n)\n\nscore = (score1+score2+score3+score4) / 4\nprint(f'score: {score}')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:43.552603Z","iopub.execute_input":"2021-07-28T20:11:43.552926Z","iopub.status.idle":"2021-07-28T20:11:52.610368Z","shell.execute_reply.started":"2021-07-28T20:11:43.552898Z","shell.execute_reply":"2021-07-28T20:11:52.609546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### CAT + LGBM","metadata":{"execution":{"iopub.status.busy":"2021-07-21T07:29:39.930217Z","iopub.execute_input":"2021-07-21T07:29:39.931089Z","iopub.status.idle":"2021-07-21T07:29:39.937416Z","shell.execute_reply.started":"2021-07-21T07:29:39.93093Z","shell.execute_reply":"2021-07-21T07:29:39.935961Z"}}},{"cell_type":"code","source":"import pickle\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import mean_absolute_error\n\ndef fit_lgbm(x_train, y_train, x_valid, y_valid, target, params: dict=None, verbose=100):\n    oof_pred_lgb = np.zeros(len(y_valid), dtype=np.float32)\n    oof_pred_cat = np.zeros(len(y_valid), dtype=np.float32)\n    #../input/mbl-catboot-test\n    if os.path.isfile(f'../input/mbl-catboot-test/model_lgb_{target}.pkl'):\n        with open(f'../input/mbl-catboot-test/model_lgb_{target}.pkl', 'rb') as fin:\n            print('open CAT', target)\n            model = pickle.load(fin)\n    else:\n    \n        model = lgbm.LGBMRegressor(**params)\n        model.fit(x_train, y_train, \n            eval_set=[(x_valid, y_valid)],  \n            early_stopping_rounds=verbose, \n            verbose=verbose)\n\n        with open(f'model_lgb_{target}.pkl', 'wb') as handle:\n            pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n    oof_pred_lgb = model.predict(x_valid)\n    score_lgb = mean_absolute_error(oof_pred_lgb, y_valid)\n    print('mae:', score_lgb)\n    \n    if os.path.isfile(f'../input/mbl-catboot-test/model_cb_{target}.pkl'):\n        with open(f'../input/mbl-catboot-test/model_cb_{target}.pkl', 'rb') as fin:\n            print('open LGBM 2', target)\n            model_cb = pickle.load(fin)\n    else:\n    \n        model_cb = CatBoostRegressor(\n                    n_estimators=2000,\n                    learning_rate=0.05,\n                    loss_function='MAE',\n                    eval_metric='MAE',\n                    max_bin=50,\n                    subsample=0.9,\n                    colsample_bylevel=0.5,\n                    verbose=100)\n\n        model_cb.fit(x_train, y_train, use_best_model=True,\n                         eval_set=(x_valid, y_valid),\n                         early_stopping_rounds=25)\n\n        with open(f'model_cb_{target}.pkl', 'wb') as handle:\n            pickle.dump(model_cb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n    \n    oof_pred_cat = model_cb.predict(x_valid)\n    score_cat = mean_absolute_error(oof_pred_cat, y_valid)\n    print('mae:', score_cat)\n    \n    return oof_pred_lgb, model, oof_pred_cat, model_cb, score_lgb, score_cat","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:52.611808Z","iopub.execute_input":"2021-07-28T20:11:52.612384Z","iopub.status.idle":"2021-07-28T20:11:52.815436Z","shell.execute_reply.started":"2021-07-28T20:11:52.612344Z","shell.execute_reply":"2021-07-28T20:11:52.814666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training lightgbm\nparams = {\n'boosting_type': 'gbdt',\n'objective':'mae',\n'subsample': 0.5,\n'subsample_freq': 1,\n'learning_rate': 0.03,\n'num_leaves': 2**11-1,\n'min_data_in_leaf': 2**12-1,\n'feature_fraction': 0.5,\n'max_bin': 100,\n'n_estimators': 2500,\n'boost_from_average': False,\n\"random_seed\":42,\n}\n\noof_pred_lgb1, model_lgb1, oof_pred_cat1, model_cb1, score_lgb1, score_cat1 = fit_lgbm(\n    x_train, y_train['target1'],\n    x_valid, y_valid['target1'],\n    1, params\n)\n\noof_pred_lgb2, model_lgb2, oof_pred_cat2, model_cb2, score_lgb2, score_cat2 = fit_lgbm(\n    x_train_2, y_train['target2'],\n    x_valid_2, y_valid['target2'],\n    2, params\n)\n\noof_pred_lgb3, model_lgb3, oof_pred_cat3, model_cb3, score_lgb3, score_cat3 = fit_lgbm(\n    x_train_2, y_train['target3'],\n    x_valid_2, y_valid['target3'],\n    3, params\n)\noof_pred_lgb4, model_lgb4, oof_pred_cat4, model_cb4, score_lgb4, score_cat4= fit_lgbm(\n    x_train_2, y_train['target4'],\n    x_valid_2, y_valid['target4'],\n    4, params\n)\n\nscore = (score_lgb1+score_lgb2+score_lgb3+score_lgb4) / 4\nprint(f'LightGBM score: {score}')\n\nscore = (score_cat1+score_cat2+score_cat3+score_cat4) / 4\nprint(f'Catboost score: {score}')","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:11:52.816755Z","iopub.execute_input":"2021-07-28T20:11:52.817258Z","iopub.status.idle":"2021-07-28T20:12:27.189146Z","shell.execute_reply.started":"2021-07-28T20:11:52.817216Z","shell.execute_reply":"2021-07-28T20:12:27.187957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SUBMIT","metadata":{"execution":{"iopub.status.busy":"2021-07-09T11:39:17.423592Z","iopub.execute_input":"2021-07-09T11:39:17.423906Z","iopub.status.idle":"2021-07-09T11:39:17.428038Z","shell.execute_reply.started":"2021-07-09T11:39:17.42388Z","shell.execute_reply":"2021-07-09T11:39:17.426924Z"}}},{"cell_type":"code","source":"import mlb","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:12:27.190496Z","iopub.execute_input":"2021-07-28T20:12:27.190814Z","iopub.status.idle":"2021-07-28T20:12:27.195053Z","shell.execute_reply.started":"2021-07-28T20:12:27.190783Z","shell.execute_reply":"2021-07-28T20:12:27.194004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rosters_cols_test = ['playerId', 'teamId', 'status']\nscores_cols_test = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n       'inheritedRunnersScored', 'catchersInterferencePitching',\n       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n       'assists', 'putOuts', 'errors', 'chances']","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:12:27.196713Z","iopub.execute_input":"2021-07-28T20:12:27.197016Z","iopub.status.idle":"2021-07-28T20:12:27.212538Z","shell.execute_reply.started":"2021-07-28T20:12:27.196988Z","shell.execute_reply":"2021-07-28T20:12:27.211693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null = np.nan\ntrue = True\nfalse = False\n\nimport mlb\nimport copy\nenv = mlb.make_env() # initialize the environment\niter_test = env.iter_test() # iterator which loops over each date in test set\n\nfor (test_df, sample_prediction_df) in iter_test: # make predictions here\n#     #+++++++++++++++++++++++++++++++\n    sub = copy.deepcopy(sample_prediction_df.reset_index())\n#     sub = copy.deepcopy(sample_prediction_df.reset_index())\n#     #++++++++++++++++++++++++++++++\n    sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n        \n    # вынимаем код игрока из индекса\n    sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[1]))\n     # вынимаем дату из индекса\n    sample_prediction_df['date'] = sample_prediction_df['date_playerId']\\\n                                        .map(lambda x: int(x.split('_')[0]))\n    sample_prediction_df['date'] = pd.to_datetime(sample_prediction_df['date'], format = '%Y%m%d')\n    #display(sample_prediction_df)\n   \n    # Dealing with missing values\n    if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n        test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n    else:\n        test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in rosters.columns:\n            if col == 'playerId': continue\n            test_rosters[col] = np.nan\n    #display(test_df)\n    \n    if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n        test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n    else:\n        test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n        for col in scores.columns:\n            if col == 'playerId': continue\n            test_scores[col] = np.nan\n    \n    test_scores = test_scores.groupby('playerId').sum().reset_index()\n    # получаем айдишники игроков и даты\n    test = sample_prediction_df[['playerId','date']].copy()\n    # обогащаем твитером играков\n    test['twit_year'] = test['date'].dt.year\n    test = test.merge(playerTwitter_test[playerTwitter_cols], on=['playerId', 'twit_year'], how='left')\n    test.fillna({'numberOfFollowers':0, 'twit_med_f':0 , 'twit_min_f':0 ,'twit_max_f':0 ,'twit_trend':0 }, inplace=True)\n        \n    # обогащаем данными игроков\n    test = test.merge(players[players_cols], on='playerId', how='left')\n    # обогощаем статусом\n    test = test.merge(test_rosters[rosters_cols_test], on='playerId', how='left')\n    \n    #Here+++++++++++++++++++++++\n    # обогащаем твитером команд\n    test = test.merge(teamTwitter_test[teamTwitter_cols], on=['teamId', 'twit_year'], how='left')\n    test.fillna({'team_numberOfFollowers':0, 'team_twit_med_f':0 , 'team_twit_min_f':0 ,'team_twit_max_f':0 ,'team_twit_trend':0 }, inplace=True)\n    #Here+++++++++++++++++++++++   \n    \n    # обогащаем периодом\n    test_season = test.copy() \n    #display(test_season)\n    test_season['period'] = test_season['date']\n    test_season = test_season.set_index('period').to_period('D')\n    test_season = udate_season(test_season)\n    \n    season_col = ['playerId','inSeason','seasonPart']\n    test = test.merge(test_season[season_col], on=['playerId'], how='left')\n    #display(test)\n    # Обогащаем годом рождения\n    test = udate_year_old(test)\n    #display(test)\n    #\n    # обогащаем стат данными\n    test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n\n    # обогащаем данными игры\n    #test = test.merge(test_scores[scores_cols], on='playerId', how='left')\n    test = test.merge(test_scores[scores_cols_test], on='playerId', how='left')\n    \n    #test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n    test['label_teamId'] = test['teamId'].map(teamid2num)\n    test['label_status'] = test['status'].map(status2num)\n    #display(test)\n    test_X = test[feature_cols]\n    \n#     # predict cat and lgbm\n#     pred_lgd1 = model_lgb1.predict(test_X)\n#     pred_lgd2 = model_lgb2.predict(test_X)\n#     pred_lgd3 = model_lgb3.predict(test_X)\n#     pred_lgd4 = model_lgb4.predict(test_X)\n    \n#     pred_cat1 = model_cb1.predict(test_X)\n#     pred_cat2 = model_cb2.predict(test_X)\n#     pred_cat3 = model_cb3.predict(test_X)\n#     pred_cat4 = model_cb4.predict(test_X)\n    \n   # predict 1 LGBM + GAT \n      \n    pred1 = model1.predict(test_X)\n    pred_lgd1 = model_lgb1.predict(test_X)\n    pred_cat1 = model_cb1.predict(test_X)\n    \n    \n    #test['target1'] = np.clip(pred1,0,100)\n    test['target1'] = np.clip(pred1,0,100)\n    \n    # here++++++++++++++++++++++++\n    test_team_tag =  test.groupby(['label_teamId','date'])['target1'].agg('sum').reset_index()\n    test_team_tag.columns = ['label_teamId', 'date','targ_team']\n    test = test.merge(test_team_tag, on=['label_teamId', 'date'], how='left')\n    test.fillna({'targ_team':0}, inplace=True)\n    # here++++++++++++++++++++++++    \n    \n    test_X = test[feature_cols_2]\n   \n    # predict 2,3,4 LGBM + GAT \n    pred2 = model2.predict(test_X)\n    pred3 = model3.predict(test_X)\n    pred4 = model4.predict(test_X)\n    \n    pred_lgd2 = model_lgb2.predict(test_X)\n    pred_lgd3 = model_lgb3.predict(test_X)\n    pred_lgd4 = model_lgb4.predict(test_X)\n    \n    pred_cat2 = model_cb2.predict(test_X)\n    pred_cat3 = model_cb3.predict(test_X)\n    pred_cat4 = model_cb4.predict(test_X)\n      \n       \n    # merge submission\n    #sample_prediction_df = sample_prediction_df.drop(['date'],axis =1)\n    \n#     sample_prediction_df['target1'] = np.clip(pred1, 0, 100)\n#     sample_prediction_df['target2'] = np.clip(pred2, 0, 100)\n#     sample_prediction_df['target3'] = np.clip(pred3, 0, 100)\n#     sample_prediction_df['target4'] = np.clip(pred4, 0, 100)\n#     sample_prediction_df = sample_prediction_df.fillna(0.)\n    \n     # submission  LGBM 1 + CAT + LGBM2\n    sample_prediction_df['target1'] = 0.34*np.clip(pred1, 0, 100)+0.33*np.clip(pred_lgd1, 0, 100)+0.34*np.clip(pred_cat1, 0, 100)\n    sample_prediction_df['target2'] = 0.34*np.clip(pred2, 0, 100)+0.33*np.clip(pred_lgd2, 0, 100)+0.34*np.clip(pred_cat2, 0, 100)\n    sample_prediction_df['target3'] = 0.34*np.clip(pred3, 0, 100)+0.33*np.clip(pred_lgd3, 0, 100)+0.34*np.clip(pred_cat3, 0, 100)\n    sample_prediction_df['target4'] = 0.34*np.clip(pred4, 0, 100)+0.33*np.clip(pred_lgd4, 0, 100)+0.34*np.clip(pred_cat4, 0, 100)\n\n#     sample_prediction_df['target1'] = 0.4*np.clip(pred1, 0, 100)+0.3*np.clip(pred_lgd1, 0, 100)+0.3*np.clip(pred_cat1, 0, 100)\n#     sample_prediction_df['target2'] = 0.3*np.clip(pred2, 0, 100)+0.3*np.clip(pred_lgd2, 0, 100)+0.4*np.clip(pred_cat2, 0, 100)\n#     sample_prediction_df['target3'] = 0.4*np.clip(pred3, 0, 100)+0.3*np.clip(pred_lgd3, 0, 100)+0.3*np.clip(pred_cat3, 0, 100)\n#     sample_prediction_df['target4'] = 0.3*np.clip(pred4, 0, 100)+0.3*np.clip(pred_lgd4, 0, 100)+0.4*np.clip(pred_cat4, 0, 100)\n\n#     sample_prediction_df['target1'] = 1*np.clip(pred1, 0, 100)+0*np.clip(pred_lgd1, 0, 100)+0*np.clip(pred_cat1, 0, 100)\n#     sample_prediction_df['target2'] = 0*np.clip(pred2, 0, 100)+0*np.clip(pred_lgd2, 0, 100)+1*np.clip(pred_cat2, 0, 100)\n#     sample_prediction_df['target3'] = 1*np.clip(pred3, 0, 100)+0*np.clip(pred_lgd3, 0, 100)+0*np.clip(pred_cat3, 0, 100)\n#     sample_prediction_df['target4'] = 0*np.clip(pred4, 0, 100)+0*np.clip(pred_lgd4, 0, 100)+1*np.clip(pred_cat4, 0, 100)\n\n    sample_prediction_df = sample_prediction_df.fillna(0.)\n           \n    #+++++++++++++++++++++++++++++++++++++\n        \n    sub_fe, eval_dt = test_lag(sub)\n    sub_fe = sub_fe.merge(LAST_MED_DF, on=\"playerId\", how=\"left\")\n    sub_fe = sub_fe.fillna(0.)\n    \n    _preds = 0.\n    for reg in nets:\n        _preds += reg.predict(sub_fe[FECOLS + MEDCOLS]) / NFOLDS\n    sub_fe[TGTCOLS] = np.clip(_preds, 0, 100)\n    sub.drop([\"date\"]+TGTCOLS, axis=1, inplace=True)\n    sub = sub.merge(sub_fe[[\"playerId\"]+TGTCOLS], on=\"playerId\", how=\"left\")\n    sub.drop(\"playerId\", axis=1, inplace=True)\n    sub = sub.fillna(0.)\n    #+++++++++++++++++++++++++++++++++++++\n    \n    \n    #display(sample_prediction_df)\n    del sample_prediction_df['playerId']\n    del sample_prediction_df['date']\n    #display(sample_prediction_df)\n    #env.predict(sample_prediction_df)\n    # Blending\n#     blend = pd.concat(\n#         [sub[['date_playerId']],\n#         (0.1*sub.drop('date_playerId', axis=1) + 0.9*sample_prediction_df.drop('date_playerId', axis=1))],\n#         axis=1)\n    # new  weighting ANN and LGBM+CAT\n    blend = pd.concat( [sub[['date_playerId']],\n        (0.35*sub.drop('date_playerId', axis=1) + 0.65*sample_prediction_df.drop('date_playerId', axis=1))],\n        axis=1 )\n    env.predict(blend)\n    \n      \n    # Update Available information\n       \n    sub_fe[\"EvalDate\"] = eval_dt\n    LAST = LAST.append(sub_fe)\n    LAST = LAST.drop_duplicates(subset=[\"EvalDate\",\"playerId\"], keep=\"last\")\n","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:12:27.21389Z","iopub.execute_input":"2021-07-28T20:12:27.214437Z","iopub.status.idle":"2021-07-28T20:12:42.032132Z","shell.execute_reply.started":"2021-07-28T20:12:27.214402Z","shell.execute_reply":"2021-07-28T20:12:42.030964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat(\n    [sub[['date_playerId']],\n    (sub.drop('date_playerId', axis=1) + sample_prediction_df.drop('date_playerId', axis=1)) / 2],\n    axis=1\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:12:42.033586Z","iopub.execute_input":"2021-07-28T20:12:42.034088Z","iopub.status.idle":"2021-07-28T20:12:42.062277Z","shell.execute_reply.started":"2021-07-28T20:12:42.03403Z","shell.execute_reply":"2021-07-28T20:12:42.06128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}